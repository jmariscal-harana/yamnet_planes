{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuned YAMNet: small aircraft detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio, librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Decide what type of messages are displayed by TensorFlow (ERROR, WARN, INFO, DEBUG, FATAL)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# Disable eager execution for TF1 compatibility\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tf version:  2.2.0\ntf.keras version:  2.3.0-tf\n"
    }
   ],
   "source": [
    "# TensorFlow memory allocation options:\n",
    "# # OPTION 1: \"smart\" allocation\n",
    "# config=tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth=True\n",
    "# sess=tf.Session(config=config) \n",
    "\n",
    "# OPTION 2: maximum memory allocation per session (0-1 = 0-100%)\n",
    "tf_ver = tf.__version__\n",
    "if tf_ver[0] == \"1\":\n",
    "    gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.05)\n",
    "    sess=tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "elif tf_ver[0] == \"2\":\n",
    "    gpu_options=tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.05)\n",
    "    sess=tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "# OPTION 3: ???\n",
    "#physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "# OPTION 4: ???\n",
    "#Slim/embedded versions: (https://github.com/google-research/tf-slim)\n",
    "\n",
    "print(\"tf version: \", tf.__version__)\n",
    "print(\"tf.keras version: \", tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add/append required paths\n",
    "import os, sys\n",
    "\n",
    "path_root = '/home/anakin/Models/yamnet_planes/' #path to main folder\n",
    "# path_root = input(\"Enter the path of your repository: \") # ask user for path_root\n",
    "assert os.path.exists(path_root)\n",
    "sys.path.append(path_root)\n",
    "\n",
    "path_yamnet_original = path_root+'yamnet_original/' #path to original yamnet files\n",
    "assert os.path.exists(path_yamnet_original)\n",
    "# sys.path.append(path_yamnet_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load functions\n",
    "%run \"yamnet_functions.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YAMNet (original) predictions on a single audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yamnet_original.features as features\n",
    "import yamnet_original.params as params\n",
    "import yamnet_original.yamnet as yamnet\n",
    "\n",
    "class_names = yamnet.class_names(path_yamnet_original+'yamnet_class_map.csv')\n",
    "\n",
    "params.PATCH_HOP_SECONDS = 0.96 #low values: higher accuracy but higher computational cost\n",
    "DESIRED_SR = params.SAMPLE_RATE # required by YAMNet\n",
    "\n",
    "yamnet_vis = yamnet.yamnet_frames_model(params)\n",
    "yamnet_vis.load_weights(path_root+'yamnet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Understand impact of parameters on input image and visualise\n",
    "# Load waveform\n",
    "file_name = \"/home/anakin/Datasets/airplanes_v0/training_data/plane/track_04_0000_norm.wav\"\n",
    "waveform = read_wav(file_name, DESIRED_SR, use_rosa=True)\n",
    "DESIRED_DURATION = 0.96 #[s]\n",
    "waveform = waveform[0:round(DESIRED_DURATION*DESIRED_SR)] #the last data point does not need to be included in the STFT\n",
    "\n",
    "print('Waveform size:', waveform.shape, 'and duration:', waveform.shape[0]/DESIRED_SR, '[s]\\n')\n",
    "\n",
    "# Calculate spectrogram\n",
    "log_mel_spectrogram, magnitude_spectrogram, spectrogram = features.waveform_to_log_mel_spectrogram(waveform,params,print_on=1)\n",
    "\n",
    "spectrogram = spectrogram.eval(session=sess)\n",
    "magnitude_spectrogram = magnitude_spectrogram.eval(session=sess)\n",
    "log_mel_spectrogram = log_mel_spectrogram.eval(session=sess)\n",
    "\n",
    "print('Spectrogram (complex) size (x,y):',spectrogram.shape)\n",
    "print('Spectrogram (magnitude) size (x,y):',magnitude_spectrogram.shape)\n",
    "print('Log-scaled mel spectrogram size (x,y):',log_mel_spectrogram.shape,'\\n')\n",
    " \n",
    "# Calculate features (patches)\n",
    "features_img = features.spectrogram_to_patches(log_mel_spectrogram, params, print_on=1)\n",
    "features_img = features_img.eval(session=sess)\n",
    "\n",
    "# Calculate scores\n",
    "scores, _, _ = yamnet_vis.predict(np.reshape(waveform, [1, -1]), steps=1)\n",
    "\n",
    "print('Features size (images,x,y):',features_img.shape)\n",
    "print('Scores size (images,classes):',scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_tmp = \"/home/anakin/tmp_audio.wav\"\n",
    "play_audio(file_tmp,DESIRED_SR,waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "plt.figure(figsize=(10, 15))\n",
    "\n",
    "# Plot the waveform\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(waveform)\n",
    "plt.xlim([0, len(waveform)])\n",
    "plt.xlabel('Sample index')\n",
    "plt.ylabel('[AU]')\n",
    "\n",
    "# Plot the magnitude spectrogram\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.imshow(magnitude_spectrogram.T, aspect='auto', interpolation='nearest', origin='bottom')\n",
    "plt.xlabel('Frame index')\n",
    "plt.ylabel('Frequency bin index')\n",
    "\n",
    "# Plot the log-scaled mel spectrogram\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.imshow(log_mel_spectrogram.T, aspect='auto', interpolation='nearest', origin='bottom')\n",
    "plt.xlabel('Frame index')\n",
    "plt.ylabel('Mel bin index')\n",
    "\n",
    "# Plot and label the model output scores for the top-scoring classes for each \n",
    "mean_scores = np.mean(scores, axis=0)\n",
    "top_N = 10\n",
    "top_class_indices = np.argsort(mean_scores)[::-1][:top_N]\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.imshow(scores[:, top_class_indices].T, aspect='auto', interpolation='nearest', cmap='gray_r', origin='bottom')\n",
    "# Compensate for the PATCH_HOP_SECONDS to align with log-scaled mel spectrogram\n",
    "feature_frame_step = int(round(params.PATCH_HOP_SECONDS/params.STFT_HOP_SECONDS))\n",
    "duration = log_mel_spectrogram.shape[0]/feature_frame_step\n",
    "xlim_values = -0.5 + np.array([0, duration])\n",
    "xtick_values = -0.5 + np.arange(0, scores.shape[0]+1)\n",
    "xtick_labels = params.PATCH_HOP_SECONDS*np.arange(0, scores.shape[0]+1)\n",
    "plt.xlim(xlim_values)\n",
    "plt.xticks(xtick_values, xtick_labels)\n",
    "plt.xlabel('Time [s]')\n",
    "# Label the top_N classes.\n",
    "yticks = range(0, top_N, 1)\n",
    "plt.yticks(yticks, [class_names[top_class_indices[x]] for x in yticks])\n",
    "plt.ylim(-0.5 + np.array([top_N, 0]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "Random data augmentation is performed on the original waveforms. A feature vector is generated for every waveform which will later be used to train a fully-connected classifier. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modified YAMNet model for feature extraction\n",
    "import yamnet_original.params as params\n",
    "import yamnet_modified as yamnet_modified\n",
    "\n",
    "params.PATCH_HOP_SECONDS = 0.96 #low values: higher accuracy but higher computational cost\n",
    "DESIRED_SR = params.SAMPLE_RATE # required by YAMNet\n",
    "\n",
    "yamnet_features = yamnet_modified.yamnet_frames_model(params)\n",
    "yamnet_features.load_weights(path_root+'yamnet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "0%|          | 0/16 [00:00<?, ?it/s] Loading 0     'not_plane                               '\n100%|██████████| 16/16 [06:12<00:00, 23.26s/it]\n  0%|          | 0/14 [00:00<?, ?it/s] Loading 1     'plane                                   '\n100%|██████████| 14/14 [06:42<00:00, 28.72s/it]\n"
    }
   ],
   "source": [
    "samples, labels = load_data(\"/home/anakin/Datasets/airplanes_v0/training_data/\",\n",
    "    yamnet_features,\n",
    "    num_augmentations=100,\n",
    "    max_sample_seconds=5.0,\n",
    "    DESIRED_SR=DESIRED_SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Loaded samples:  (9795, 1024) float32 (9795,)\n"
    }
   ],
   "source": [
    "# Randomise sample/label order\n",
    "import random\n",
    "\n",
    "idxs = list(range(len(labels)))\n",
    "random.shuffle(idxs)\n",
    "\n",
    "samples = [samples[i] for i in idxs]\n",
    "labels = [labels[i] for i in idxs]\n",
    "\n",
    "samples = np.array(samples)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\" Loaded samples: \" , samples.shape, samples.dtype,  labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a classifier using YAMNet's feature vector as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier definition\n",
    "from tensorflow.keras import Model, layers\n",
    "\n",
    "def yamnet_classifier(input_size=1024,\n",
    "    num_hidden=1024,\n",
    "    num_classes=2):\n",
    "    \n",
    "    input_layer = layers.Input(shape=(input_size,)) #takes a vector of size (input_size,)\n",
    "    dense_layer = layers.Dense(num_hidden, activation=None)(input_layer) #classifier layer with (num_hidden) neurons\n",
    "    classifier_layer = layers.Dense(num_classes, activation='softmax')(dense_layer) #activation layer with (num_classes) neurons\n",
    "    model = Model(inputs=input_layer, outputs=classifier_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "features_img_length = 1024\n",
    "num_hidden = 1024\n",
    "num_classes = 2\n",
    "\n",
    "yamnet_planes = yamnet_classifier(\n",
    "    input_size=features_img_length, \n",
    "    num_hidden=num_hidden,\n",
    "    num_classes=num_classes)\n",
    "\n",
    "# Optimisation configuration\n",
    "#opt = Adam(learning_rate=0.001)\n",
    "opt = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "yamnet_planes.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the classifier\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "save_best = ModelCheckpoint('top_model.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "history = yamnet_planes.fit(samples, labels, epochs=10000, validation_split=0.1, callbacks=[save_best])\n",
    "# history = yamnet_planes.fit(samples, labels, epochs=200, validation_split=0.1, callbacks=[save_best])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on holdout sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_2 (InputLayer)         [(None, 1024)]            0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 1024)              1049600   \n_________________________________________________________________\ndense_2 (Dense)              (None, 2)                 2050      \n=================================================================\nTotal params: 1,051,650\nTrainable params: 1,051,650\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# Load model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "yamnet_planes = load_model(path_root+'top_model.hdf5')\n",
    "opt = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "yamnet_planes.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "yamnet_planes.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specify class labels\n",
    "class_labels = [\"not plane\", \"plane\"]\n",
    "\n",
    "import yamnet_original.params as params\n",
    "DESIRED_SR = params.SAMPLE_RATE # required by YAMNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/anakin/Datasets/airplanes_v0/holdout_data/plane/track_04_0000_norm.wav'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    626\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 627\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid file: {0!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m         _error_check(_snd.sf_error(file_ptr),\n\u001b[0m\u001b[1;32m   1182\u001b[0m                      \"Error opening {0!r}: \".format(self.name))\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/soundfile.py\u001b[0m in \u001b[0;36m_error_check\u001b[0;34m(err, prefix)\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0merr_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_error_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1355\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error opening '/home/anakin/Datasets/airplanes_v0/holdout_data/plane/track_04_0000_norm.wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ba37787c280e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Scores for a single holdout audio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home/anakin/Datasets/airplanes_v0/holdout_data/plane/track_04_0000_norm.wav\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwaveform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDESIRED_SR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_rosa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwaveform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myamnet_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myamnet_planes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Models/yamnet_planes/yamnet_functions.py\u001b[0m in \u001b[0;36mread_wav\u001b[0;34m(fname, output_sr, use_rosa)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_rosa\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mwaveform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_sr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mwav_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PySoundFile failed. Trying audioread instead.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__audioread_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/audioread/rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \"\"\"\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/anakin/Datasets/airplanes_v0/holdout_data/plane/track_04_0000_norm.wav'"
     ]
    }
   ],
   "source": [
    "# Scores for a single holdout audio\n",
    "file_name = \"/home/anakin/Datasets/airplanes_v0/holdout_data/plane/track_04_0000_norm.wav\"\n",
    "waveform = read_wav(file_name, DESIRED_SR, use_rosa=1)\n",
    "\n",
    "scores = run_models(waveform, yamnet_features, yamnet_planes)\n",
    "winner = class_labels[scores.argmax()]\n",
    "\n",
    "print(\" Best score: {}  label: {}\".format(scores.max(), winner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scores for a holdout folder\n",
    "holdout_dir = \"/home/anakin/Datasets/airplanes_v0/holdout_data/not_plane/\"\n",
    "arr = os.listdir(holdout_dir)\n",
    "\n",
    "for fname in arr:\n",
    "    print(fname)\n",
    "    fname = holdout_dir+fname\n",
    "    waveform = read_wav(fname, DESIRED_SR, use_rosa=1)\n",
    "\n",
    "    # make file a bit longer by duplicating it \n",
    "    waveform = np.concatenate((waveform,waveform,waveform))\n",
    "    scores = run_models(waveform, yamnet_features, yamnet_planes, strip_silence=False)\n",
    "    winner_save = np.empty((0,2))\n",
    "    if scores[0] != -1:\n",
    "        winner = class_labels[scores.argmax()]\n",
    "        print(\" Best score: {}  label: {}\".format(scores.max(), winner))\n",
    "        # winner_save = np.append(winner_save,np.array([scores.max(),winner]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_array = np.empty((0, 2))\n",
    "# result = np.array([1,\"a\"])\n",
    "# result_array = np.append(result_array, [result], axis=0)\n",
    "# result_array = np.append(result_array, [result], axis=0)\n",
    "\n",
    "# result_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the model for later\n",
    "model.save(\"top_model_v3.h5\", include_optimizer=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}